{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-30 22:13:26.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.openaiwrapper.openai_wrapper\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mUpdate cost from langchain\u001b[0m\n",
      "\u001b[32m2025-03-30 22:13:27.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.openaiwrapper.get_openai_cost\u001b[0m:\u001b[36mextract_and_save_model_cost_data\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mModel cost data saved to c:\\Users\\caanp\\OneDrive\\MBA\\Repositorio\\GenAI-MBA\\src\\utils\\openaiwrapper\\model_costs.json\u001b[0m\n",
      "\u001b[32m2025-03-30 22:13:29.205\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.notebook_vs_util.vs_path\u001b[0m:\u001b[36mvs_notebook_name\u001b[0m:\u001b[36m19\u001b[0m - \u001b[34m\u001b[1mExtract the notebook name\u001b[0m\n",
      "\u001b[32m2025-03-30 22:13:29.209\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.notebook_vs_util.vs_path\u001b[0m:\u001b[36mvs_notebook_name\u001b[0m:\u001b[36m22\u001b[0m - \u001b[34m\u001b[1mExtract the notebook name: 02.llm_openai_gemini\u001b[0m\n",
      "\u001b[32m2025-03-30 22:13:29.210\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.notebook_vs_util.vs_path\u001b[0m:\u001b[36mvs_notebook_name\u001b[0m:\u001b[36m19\u001b[0m - \u001b[34m\u001b[1mExtract the notebook name\u001b[0m\n",
      "\u001b[32m2025-03-30 22:13:29.211\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.notebook_vs_util.vs_path\u001b[0m:\u001b[36mvs_notebook_name\u001b[0m:\u001b[36m22\u001b[0m - \u001b[34m\u001b[1mExtract the notebook name: 02.llm_openai_gemini\u001b[0m\n",
      "\u001b[32m2025-03-30 22:13:29.214\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.notebook_vs_util.vs_path\u001b[0m:\u001b[36mnumber_log\u001b[0m:\u001b[36m65\u001b[0m - \u001b[34m\u001b[1mThe next log number determined is: 5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from loguru import logger\n",
    "\n",
    "print(load_dotenv())\n",
    "\n",
    "sys.path.insert(1, os.path.join( os.getcwd(), \"..\" ) )\n",
    "from src.llm import multi_llm\n",
    "from src.utils.notebook_vs_util.vs_path import vs_notebook_name, number_log\n",
    "\n",
    "from src.utils.ea.exp_funcs import pricing\n",
    "\n",
    "notebook_name = vs_notebook_name()\n",
    "n = number_log(\".\\logs\")\n",
    "logger.add(f\".\\logs\\{notebook_name}_{n}.log\")\n",
    "\n",
    "n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promp enginering\n",
    "\n",
    "Prompt Techniques: \n",
    "- Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models: https://arxiv.org/pdf/2305.04091.pdf\n",
    "- Prompt page: https://www.promptingguide.ai/techniques\n",
    "- ToT: https://github.com/dave1010/tree-of-thought-prompting\n",
    "- PAL: https://www.promptingguide.ai/techniques/pal\n",
    "- CoT: https://www.promptingguide.ai/techniques/cot\n",
    "\n",
    "## Discussion\n",
    "- https://github.com/holarissun/PanelGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Data\n",
    "\n",
    "Carregando os dados de amostra com 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1 = pd.read_parquet(\"./../Dados/sample_1_Meli.parquet\")\n",
    "sample_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_emoji_reviews = sample_1.query(\"with_emojis==True and qtd_words==1\").reset_index(drop=True)\n",
    "only_emoji_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewCreatedVersion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "replyContent",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "repliedAt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "appVersion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "appId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "qtd_tokens",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "qtd_characters",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "qtd_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "list_emojis",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "qtd_emojis",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "with_emojis",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "input_$_gpt_35",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "input_$_gpt_4o",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "input_$_gpt_4o-mini",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "input_$_gpt_4_turbo",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "input_$_gpt_4",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3538b15f-6cab-4294-aaf4-e5611f3451b3",
       "rows": [
        [
         "0",
         "91f1a738-05f7-4ca8-9c7a-87e5bccf2a96",
         "2021-05-02 20:48:34",
         "üëç",
         "3",
         "10.154.2",
         null,
         null,
         "10.154.2",
         "com.mercadolibre",
         "1",
         "3",
         "1",
         "1",
         "['üëç']",
         "1",
         "True",
         "1.5e-06",
         "1.5e-05",
         "4.5e-07",
         "3e-05",
         "9e-05"
        ],
        [
         "1",
         "cc1b92e8-583f-4292-a1fd-7c950f66469c",
         "2021-06-03 19:04:21",
         "Bomüòá",
         "3",
         "10.159.4",
         null,
         null,
         "10.159.4",
         "com.mercadolibre",
         "1",
         "4",
         "4",
         "1",
         "['üòá']",
         "1",
         "True",
         "2e-06",
         "2e-05",
         "6e-07",
         "4e-05",
         "0.00012"
        ],
        [
         "2",
         "710622ac-a057-4058-93f2-a1bd586ab23b",
         "2023-09-10 14:59:14",
         "‚ù£Ô∏è",
         "5",
         "10.277.4",
         null,
         null,
         "10.277.4",
         "com.mercadolibre",
         "2",
         "3",
         "2",
         "1",
         "['‚ù£']",
         "1",
         "True",
         "1.5e-06",
         "1.5e-05",
         "4.5e-07",
         "3e-05",
         "9e-05"
        ],
        [
         "3",
         "d468e35e-3ba2-4c9f-8552-a216293da1a9",
         "2023-09-24 09:47:48",
         "üëçüëçüëçüëç",
         "5",
         "10.279.2",
         null,
         null,
         "10.279.2",
         "com.mercadolibre",
         "2",
         "12",
         "4",
         "1",
         "['üëç' 'üëç' 'üëç' 'üëç']",
         "4",
         "True",
         "6e-06",
         "6e-05",
         "1.8e-06",
         "0.00012",
         "0.00036"
        ],
        [
         "4",
         "a0f9c333-adf5-4264-8d82-25fcebb6ee23",
         "2023-09-16 21:15:00",
         "üòçüòç",
         "5",
         "10.278.2",
         null,
         null,
         "10.278.2",
         "com.mercadolibre",
         "2",
         "4",
         "2",
         "1",
         "['üòç' 'üòç']",
         "2",
         "True",
         "2e-06",
         "2e-05",
         "6e-07",
         "4e-05",
         "0.00012"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>at</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>appId</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>qtd_characters</th>\n",
       "      <th>qtd_words</th>\n",
       "      <th>list_emojis</th>\n",
       "      <th>qtd_emojis</th>\n",
       "      <th>with_emojis</th>\n",
       "      <th>input_$_gpt_35</th>\n",
       "      <th>input_$_gpt_4o</th>\n",
       "      <th>input_$_gpt_4o-mini</th>\n",
       "      <th>input_$_gpt_4_turbo</th>\n",
       "      <th>input_$_gpt_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91f1a738-05f7-4ca8-9c7a-87e5bccf2a96</td>\n",
       "      <td>2021-05-02 20:48:34</td>\n",
       "      <td>üëç</td>\n",
       "      <td>3</td>\n",
       "      <td>10.154.2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.154.2</td>\n",
       "      <td>com.mercadolibre</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[üëç]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4.500000e-07</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cc1b92e8-583f-4292-a1fd-7c950f66469c</td>\n",
       "      <td>2021-06-03 19:04:21</td>\n",
       "      <td>Bomüòá</td>\n",
       "      <td>3</td>\n",
       "      <td>10.159.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.159.4</td>\n",
       "      <td>com.mercadolibre</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[üòá]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.000000e-07</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>710622ac-a057-4058-93f2-a1bd586ab23b</td>\n",
       "      <td>2023-09-10 14:59:14</td>\n",
       "      <td>‚ù£Ô∏è</td>\n",
       "      <td>5</td>\n",
       "      <td>10.277.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.277.4</td>\n",
       "      <td>com.mercadolibre</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[‚ù£]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4.500000e-07</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d468e35e-3ba2-4c9f-8552-a216293da1a9</td>\n",
       "      <td>2023-09-24 09:47:48</td>\n",
       "      <td>üëçüëçüëçüëç</td>\n",
       "      <td>5</td>\n",
       "      <td>10.279.2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.279.2</td>\n",
       "      <td>com.mercadolibre</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[üëç, üëç, üëç, üëç]</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.800000e-06</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a0f9c333-adf5-4264-8d82-25fcebb6ee23</td>\n",
       "      <td>2023-09-16 21:15:00</td>\n",
       "      <td>üòçüòç</td>\n",
       "      <td>5</td>\n",
       "      <td>10.278.2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.278.2</td>\n",
       "      <td>com.mercadolibre</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[üòç, üòç]</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.000000e-07</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId                   at content  score  \\\n",
       "0  91f1a738-05f7-4ca8-9c7a-87e5bccf2a96  2021-05-02 20:48:34       üëç      3   \n",
       "1  cc1b92e8-583f-4292-a1fd-7c950f66469c  2021-06-03 19:04:21    Bomüòá      3   \n",
       "2  710622ac-a057-4058-93f2-a1bd586ab23b  2023-09-10 14:59:14      ‚ù£Ô∏è      5   \n",
       "3  d468e35e-3ba2-4c9f-8552-a216293da1a9  2023-09-24 09:47:48    üëçüëçüëçüëç      5   \n",
       "4  a0f9c333-adf5-4264-8d82-25fcebb6ee23  2023-09-16 21:15:00      üòçüòç      5   \n",
       "\n",
       "  reviewCreatedVersion replyContent repliedAt appVersion             appId  \\\n",
       "0             10.154.2         None      None   10.154.2  com.mercadolibre   \n",
       "1             10.159.4         None      None   10.159.4  com.mercadolibre   \n",
       "2             10.277.4         None      None   10.277.4  com.mercadolibre   \n",
       "3             10.279.2         None      None   10.279.2  com.mercadolibre   \n",
       "4             10.278.2         None      None   10.278.2  com.mercadolibre   \n",
       "\n",
       "   sentiment  ...  qtd_characters  qtd_words   list_emojis qtd_emojis  \\\n",
       "0          1  ...               1          1           [üëç]          1   \n",
       "1          1  ...               4          1           [üòá]          1   \n",
       "2          2  ...               2          1           [‚ù£]          1   \n",
       "3          2  ...               4          1  [üëç, üëç, üëç, üëç]          4   \n",
       "4          2  ...               2          1        [üòç, üòç]          2   \n",
       "\n",
       "   with_emojis  input_$_gpt_35  input_$_gpt_4o  input_$_gpt_4o-mini  \\\n",
       "0         True        0.000002        0.000015         4.500000e-07   \n",
       "1         True        0.000002        0.000020         6.000000e-07   \n",
       "2         True        0.000002        0.000015         4.500000e-07   \n",
       "3         True        0.000006        0.000060         1.800000e-06   \n",
       "4         True        0.000002        0.000020         6.000000e-07   \n",
       "\n",
       "   input_$_gpt_4_turbo  input_$_gpt_4  \n",
       "0              0.00003        0.00009  \n",
       "1              0.00004        0.00012  \n",
       "2              0.00003        0.00009  \n",
       "3              0.00012        0.00036  \n",
       "4              0.00004        0.00012  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_emoji_reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Prompts and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = \"mercado livre\"\n",
    "\n",
    "prompt_tot = \"\"\"3 experts are discussing the question with a panel discussion, trying to solve it step by step, and make sure the result is correct and avoid penalty.\n",
    "\n",
    "The question is...                        \n",
    "            \n",
    "```{review}```\n",
    "\n",
    "What is the sentiment of the {app} app review? Positive, negative, or neutral?\n",
    "\n",
    "Output the result as a JSON object, including the `Sentimento` and `Justificativa`. Answer in portuguese.\"\"\"\n",
    "\n",
    "zero_shot_prompt =  \"\"\"\n",
    "\"Analyze the sentiment of the following {app} app review text, classifying it as positive, negative, or neutral.\n",
    "\n",
    "```{review}```\n",
    "\n",
    "Output the result as a JSON object, including the `Sentimento` and `Justificativa`. Answer in portuguese.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "            \"prompt_tot\":prompt_tot,\n",
    "            \"zero_shot_prompt\":zero_shot_prompt\n",
    "           }\n",
    "\n",
    "models = [\"gpt-3.5-turbo\",\"gpt-4o\", \"gpt-4o-mini\"]\n",
    "# models = [\"gpt-3.5-turbo\",\"gpt-4o\",\"gemini-1.5-pro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-30 22:14:53.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mmodelo: gpt-3.5-turbo - version: gpt-3.5-turbo-0125\u001b[0m\n",
      "\u001b[32m2025-03-30 22:14:54.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mmodelo: gpt-4o - version: gpt-4o-2024-08-06\u001b[0m\n",
      "\u001b[32m2025-03-30 22:14:54.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mmodelo: gpt-4o-mini - version: gpt-4o-mini-2024-07-18\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "llm_op  = OpenAI()\n",
    "\n",
    "for model in models:\n",
    "        saida = llm_op.chat.completions.create(messages=[\n",
    "                                        {\"role\": \"system\", \"content\": \"\"},\n",
    "                                        {\"role\": \"user\", \"content\": \"hola\"},\n",
    "                                        ],\n",
    "                                model = model )\n",
    "        \n",
    "        logger.info(f\"modelo: {model} - version: {saida.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3 LLM and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.1 LLM\n",
    "\n",
    "Class to use Gemini and OpenAI.\n",
    "\n",
    "- OpenAI is paid. The cost depends on the model.\n",
    "- Gemini is free, but it has quota limit per model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm  = multi_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.2 Sentiment Analysis\n",
    "\n",
    "- The execution 2 spends more time than execution 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 20)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = only_emoji_reviews[['reviewId', 'content', 'score']]\n",
    "\n",
    "sample_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def execute_models_prompts(df:DataFrame , models:list, prompts: dict, app:str = \"Mercado Livre\"):\n",
    "    \n",
    "    df_ = df.copy()\n",
    "\n",
    "    for n, model in enumerate(models, start=1):\n",
    "        \n",
    "        logger.debug(f\"{n}/{len(models)}. {model}\")\n",
    "        \n",
    "        for k, prompt_name__prompt in enumerate(prompts.items(), start=1):\n",
    "            \n",
    "            prompt_name, prompt  = prompt_name__prompt\n",
    "            \n",
    "            logger.debug(f\"\\t{k}/{len(prompts)}. {prompt_name}\")\n",
    "\n",
    "        \n",
    "            for m, idx__row in enumerate(df_.iterrows(), start=1):\n",
    "                \n",
    "                idx, row = idx__row\n",
    "                \n",
    "                # print(f\"\\t\\t{m}/{len(df_)}.\")\n",
    "                \n",
    "                \n",
    "                review = row[\"content\"]\n",
    "                prompt_anl = prompt.format(app = app, review = review )\n",
    "                \n",
    "                try:\n",
    "                \n",
    "                    result, usage = llm.response(model = model , user_message = prompt_anl, json_output=True)\n",
    "                    \n",
    "                    j_result = json.loads(result)\n",
    "                    \n",
    "                    ## Result\n",
    "                    df_.loc[idx,f\"Sentiment__{prompt_name}__{model}\"] = j_result[\"Sentimento\"]\n",
    "                    df_.loc[idx,f\"Justificativa__{prompt_name}__{model}\"] = j_result[\"Justificativa\"]\n",
    "                    ## Cost\n",
    "                    df_.loc[idx,f\"usage_completion_tokens__{prompt_name}__{model}\"] = usage[\"completion_tokens\"]\n",
    "                    df_.loc[idx,f\"usage_prompt_tokens__{prompt_name}__{model}\"] = usage[\"prompt_tokens\"]\n",
    "                    df_.loc[idx,f\"usage_total_tokens__{prompt_name}__{model}\"] = usage[\"total_tokens\"]\n",
    "                    df_.loc[idx,f\"usage_total_cost__{prompt_name}__{model}\"] = usage[\"total_cost\"]\n",
    "                \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error: {e}\")\n",
    "                \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-27 22:09:19.390\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1m1/3. gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-01-27 22:09:19.391\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1m\t1/2. prompt_tot\u001b[0m\n",
      "\u001b[32m2025-01-27 22:35:23.167\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1m\t2/2. zero_shot_prompt\u001b[0m\n",
      "\u001b[32m2025-01-27 23:38:49.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1m2/3. gpt-4o\u001b[0m\n",
      "\u001b[32m2025-01-27 23:38:49.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1m\t1/2. prompt_tot\u001b[0m\n",
      "\u001b[32m2025-01-28 09:36:31.582\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1m\t2/2. zero_shot_prompt\u001b[0m\n",
      "\u001b[32m2025-01-28 14:11:12.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1m3/3. gpt-3.5-turbo\u001b[0m\n",
      "\u001b[32m2025-01-28 14:11:12.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1m\t1/2. prompt_tot\u001b[0m\n",
      "\u001b[32m2025-01-28 17:07:24.593\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m44\u001b[0m - \u001b[31m\u001b[1mError: Unterminated string starting at: line 3 column 22 (char 53)\u001b[0m\n",
      "\u001b[32m2025-01-28 17:16:46.702\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_models_prompts\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1m\t2/2. zero_shot_prompt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_r = execute_models_prompts( sample_1 , models[::-1] , prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.to_parquet(f\"./../Dados/result_analyzer_{n}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r = pd.read_parquet(f\"./../Dados/result_analyzer_{n}.parquet\")\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens ($USD)</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modelo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>usage_total_cost__prompt_tot__gpt-3.5-turbo</th>\n",
       "      <td>0.183303</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usage_total_cost__prompt_tot__gpt-4o</th>\n",
       "      <td>1.005578</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usage_total_cost__prompt_tot__gpt-4o-mini</th>\n",
       "      <td>0.052382</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usage_total_cost__zero_shot_prompt__gpt-3.5-turbo</th>\n",
       "      <td>0.164818</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usage_total_cost__zero_shot_prompt__gpt-4o</th>\n",
       "      <td>0.871123</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usage_total_cost__zero_shot_prompt__gpt-4o-mini</th>\n",
       "      <td>0.047547</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens ($USD)  lines\n",
       "modelo                                                                 \n",
       "usage_total_cost__prompt_tot__gpt-3.5-turbo             0.183303    978\n",
       "usage_total_cost__prompt_tot__gpt-4o                    1.005578    978\n",
       "usage_total_cost__prompt_tot__gpt-4o-mini               0.052382    978\n",
       "usage_total_cost__zero_shot_prompt__gpt-3.5-turbo       0.164818    978\n",
       "usage_total_cost__zero_shot_prompt__gpt-4o              0.871123    978\n",
       "usage_total_cost__zero_shot_prompt__gpt-4o-mini         0.047547    978"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_model_1, total_1 = pricing(df_r, [x for x in df_r.columns if \"total_cost\" in x] )\n",
    "by_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-28 21:16:09.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1m\n",
      "\n",
      "                                                   tokens ($USD)  lines\n",
      "modelo                                                                 \n",
      "usage_total_cost__prompt_tot__gpt-3.5-turbo             0.183303    978\n",
      "usage_total_cost__prompt_tot__gpt-4o                    1.005578    978\n",
      "usage_total_cost__prompt_tot__gpt-4o-mini               0.052382    978\n",
      "usage_total_cost__zero_shot_prompt__gpt-3.5-turbo       0.164818    978\n",
      "usage_total_cost__zero_shot_prompt__gpt-4o              0.871123    978\n",
      "usage_total_cost__zero_shot_prompt__gpt-4o-mini         0.047547    978\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"\\n\\n{by_model_1}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-28 21:16:09.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1m\n",
      "\n",
      "tokens ($USD)       2.324748\n",
      "lines            5868.000000\n",
      "dtype: float64\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"\\n\\n{total_1}\\n\\n\")\n",
    "# total_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_colwidth',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Positivo    356\n",
       "Negativo    320\n",
       "Neutro      302\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r[\"Sentiment\"] = df_r[\"sentiment\"].apply(lambda x: \"Negativo\" if x==0 else \"Neutro\" if x==1 else \"Positivo\")\n",
    "df_r[\"Sentiment\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_cols = [x for x in df_r.columns if \"Sentiment_\" in x]\n",
    "\n",
    "for sent_col in sentiment_cols:\n",
    "    \n",
    "    df_r[f\"{sent_col}_pred\"] = df_r[sent_col].apply(lambda x: 0 if x==\"Negativo\" else 1 if x==\"Neutro\" else 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentiment__prompt_tot__gpt-4o-mini_pred',\n",
       " 'Sentiment__zero_shot_prompt__gpt-4o-mini_pred',\n",
       " 'Sentiment__prompt_tot__gpt-4o_pred',\n",
       " 'Sentiment__zero_shot_prompt__gpt-4o_pred',\n",
       " 'Sentiment__prompt_tot__gpt-3.5-turbo_pred',\n",
       " 'Sentiment__zero_shot_prompt__gpt-3.5-turbo_pred']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [x for x in df_r.columns if \"Sentiment__\" and \"pred\" in x]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_confusion_matrix(confusion_matrix, label):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('Sentimento Verdadeiro')\n",
    "  plt.xlabel('Sentimento Predito')\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  \n",
    "  plt.savefig(f\"./../Results/{label}.png\")\n",
    "  \n",
    "  plt.clf()\n",
    "  plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentiment__prompt_tot__gpt-3.5-turbo_pred',\n",
       " 'Sentiment__zero_shot_prompt__gpt-3.5-turbo_pred',\n",
       " 'Sentiment__prompt_tot__gpt-4o_pred',\n",
       " 'Sentiment__zero_shot_prompt__gpt-4o_pred']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Sentiment__prompt_tot__gpt-3.5-turbo_pred',\n",
    " 'Sentiment__zero_shot_prompt__gpt-3.5-turbo_pred',\n",
    " 'Sentiment__prompt_tot__gpt-4o_pred',\n",
    " 'Sentiment__zero_shot_prompt__gpt-4o_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Negativo\",\"Neutro\",\"Positivo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resultado in results:\n",
    "\n",
    "  cm = confusion_matrix(df_r[\"sentiment\"], df_r[resultado])\n",
    "\n",
    "  \n",
    "  df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    \n",
    "  show_confusion_matrix(df_cm, label=resultado + f\"__round_{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment__prompt_tot__gpt-4o-mini_pred\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.50      0.95      0.65       320\n",
      "      Neutro       0.50      0.03      0.06       302\n",
      "    Positivo       0.74      0.72      0.73       356\n",
      "\n",
      "    accuracy                           0.58       978\n",
      "   macro avg       0.58      0.57      0.48       978\n",
      "weighted avg       0.59      0.58      0.50       978\n",
      "\n",
      "===================================================\n",
      "Sentiment__zero_shot_prompt__gpt-4o-mini_pred\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.34      0.26      0.29       320\n",
      "      Neutro       0.41      0.03      0.06       302\n",
      "    Positivo       0.42      0.84      0.56       356\n",
      "\n",
      "    accuracy                           0.40       978\n",
      "   macro avg       0.39      0.38      0.30       978\n",
      "weighted avg       0.39      0.40      0.32       978\n",
      "\n",
      "===================================================\n",
      "Sentiment__prompt_tot__gpt-4o_pred\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.55      0.94      0.69       320\n",
      "      Neutro       0.44      0.14      0.21       302\n",
      "    Positivo       0.77      0.73      0.75       356\n",
      "\n",
      "    accuracy                           0.62       978\n",
      "   macro avg       0.59      0.60      0.55       978\n",
      "weighted avg       0.60      0.62      0.57       978\n",
      "\n",
      "===================================================\n",
      "Sentiment__zero_shot_prompt__gpt-4o_pred\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.55      0.95      0.70       320\n",
      "      Neutro       0.45      0.18      0.26       302\n",
      "    Positivo       0.78      0.67      0.73       356\n",
      "\n",
      "    accuracy                           0.61       978\n",
      "   macro avg       0.59      0.60      0.56       978\n",
      "weighted avg       0.60      0.61      0.57       978\n",
      "\n",
      "===================================================\n",
      "Sentiment__prompt_tot__gpt-3.5-turbo_pred\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.53      0.93      0.67       320\n",
      "      Neutro       0.43      0.20      0.27       302\n",
      "    Positivo       0.80      0.64      0.71       356\n",
      "\n",
      "    accuracy                           0.60       978\n",
      "   macro avg       0.59      0.59      0.55       978\n",
      "weighted avg       0.60      0.60      0.56       978\n",
      "\n",
      "===================================================\n",
      "Sentiment__zero_shot_prompt__gpt-3.5-turbo_pred\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.53      0.94      0.67       320\n",
      "      Neutro       0.39      0.12      0.19       302\n",
      "    Positivo       0.76      0.66      0.71       356\n",
      "\n",
      "    accuracy                           0.59       978\n",
      "   macro avg       0.56      0.57      0.52       978\n",
      "weighted avg       0.57      0.59      0.54       978\n",
      "\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "for resultado in results:\n",
    "\n",
    "    print(resultado)\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(df_r[\"sentiment\"],  df_r[resultado] , target_names = class_names ))\n",
    "    print(\"===================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-28 21:16:16.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSentiment__prompt_tot__gpt-4o-mini_pred\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.50      0.95      0.65       320\n",
      "      Neutro       0.50      0.03      0.06       302\n",
      "    Positivo       0.74      0.72      0.73       356\n",
      "\n",
      "    accuracy                           0.58       978\n",
      "   macro avg       0.58      0.57      0.48       978\n",
      "weighted avg       0.59      0.58      0.50       978\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1m=====================================\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSentiment__zero_shot_prompt__gpt-4o-mini_pred\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.34      0.26      0.29       320\n",
      "      Neutro       0.41      0.03      0.06       302\n",
      "    Positivo       0.42      0.84      0.56       356\n",
      "\n",
      "    accuracy                           0.40       978\n",
      "   macro avg       0.39      0.38      0.30       978\n",
      "weighted avg       0.39      0.40      0.32       978\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1m=====================================\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSentiment__prompt_tot__gpt-4o_pred\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.55      0.94      0.69       320\n",
      "      Neutro       0.44      0.14      0.21       302\n",
      "    Positivo       0.77      0.73      0.75       356\n",
      "\n",
      "    accuracy                           0.62       978\n",
      "   macro avg       0.59      0.60      0.55       978\n",
      "weighted avg       0.60      0.62      0.57       978\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1m=====================================\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSentiment__zero_shot_prompt__gpt-4o_pred\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.55      0.95      0.70       320\n",
      "      Neutro       0.45      0.18      0.26       302\n",
      "    Positivo       0.78      0.67      0.73       356\n",
      "\n",
      "    accuracy                           0.61       978\n",
      "   macro avg       0.59      0.60      0.56       978\n",
      "weighted avg       0.60      0.61      0.57       978\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1m=====================================\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSentiment__prompt_tot__gpt-3.5-turbo_pred\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.53      0.93      0.67       320\n",
      "      Neutro       0.43      0.20      0.27       302\n",
      "    Positivo       0.80      0.64      0.71       356\n",
      "\n",
      "    accuracy                           0.60       978\n",
      "   macro avg       0.59      0.59      0.55       978\n",
      "weighted avg       0.60      0.60      0.56       978\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1m=====================================\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSentiment__zero_shot_prompt__gpt-3.5-turbo_pred\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.53      0.94      0.67       320\n",
      "      Neutro       0.39      0.12      0.19       302\n",
      "    Positivo       0.76      0.66      0.71       356\n",
      "\n",
      "    accuracy                           0.59       978\n",
      "   macro avg       0.56      0.57      0.52       978\n",
      "weighted avg       0.57      0.59      0.54       978\n",
      "\u001b[0m\n",
      "\u001b[32m2025-01-28 21:16:16.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1m=====================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for resultado in results:\n",
    "\n",
    "    logger.info(f\"{resultado}\\n\")\n",
    "    logger.info(classification_report(df_r[\"sentiment\"],  df_r[resultado] , target_names = class_names ))\n",
    "    logger.info(f\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r.query(f\"sentiment==1 and `Sentiment__zero_shot_prompt__gpt-3.5-turbo`=='Positivo'\")[[\"content\",\"sentiment\",\"Sentiment__zero_shot_prompt__gpt-3.5-turbo\",\"Justificativa__zero_shot_prompt__gpt-3.5-turbo\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(df_r[\"sentiment\"],  df_r[\"Sentiment__zero_shot_prompt__gpt-4o_pred\"] , target_names = class_names ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(df_r[\"sentiment\"],  df_r[\"Sentiment__prompt_tot__gpt-4o_pred\"] , target_names = class_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(df_r[\"sentiment\"],  df_r[\"Sentiment__zero_shot_prompt__gpt-3.5-turbo_pred\"] , target_names = class_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(df_r[\"sentiment\"],  df_r[\"Sentiment__prompt_tot__gpt-3.5-turbo_pred\"] , target_names = class_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x for x in df_r.columns if \"Sentiment_\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
