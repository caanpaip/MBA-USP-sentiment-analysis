{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promp enginering\n",
    "\n",
    "Prompt Techniques: \n",
    "- Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models: https://arxiv.org/pdf/2305.04091.pdf\n",
    "- Prompt page: https://www.promptingguide.ai/techniques\n",
    "- ToT: https://github.com/dave1010/tree-of-thought-prompting\n",
    "- PAL: https://www.promptingguide.ai/techniques/pal\n",
    "- CoT: https://www.promptingguide.ai/techniques/cot\n",
    "\n",
    "## Discussion\n",
    "- https://github.com/holarissun/PanelGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-27 20:35:09.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.openaiwrapper.openai_wrapper\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mUpdate cost from langchain\u001b[0m\n",
      "\u001b[32m2025-01-27 20:35:10.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.openaiwrapper.get_openai_cost\u001b[0m:\u001b[36mextract_and_save_model_cost_data\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mModel cost data saved to c:\\Users\\caanp\\OneDrive\\MBA\\Repositorio\\GenAI_MBA\\src\\utils\\openaiwrapper\\model_costs.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(1, os.path.join( os.getcwd(), \"..\" ) )\n",
    "from src.utils.openaiwrapper.openai_wrapper import OpenAIWrapper\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_openai = OpenAIWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ToT: Example\n",
    "\n",
    "result, usage =call_openai.chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Imagine three different experts are answering this question.\n",
    "All experts will write down 1 step of their thinking,\n",
    "then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realises they're wrong at any point then they leave.\n",
    "The question is...            \n",
    "            \n",
    "            \n",
    "```gostei do app, ficou mas bonito, mas não adiante ser bonito se não funciona para nada```\n",
    "Qual é os sentimento no texto. positivo, negativo ou neutro?\n",
    "\n",
    "return the result in json format with the sentiment and expert discussion\n",
    "\"\"\"\n",
    "\n",
    ",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s how the three experts might discuss the sentiment of the provided text and the outcome in JSON format:\n",
      "\n",
      "### Expert Discussion Steps\n",
      "\n",
      "**Expert 1:**\n",
      "- Step 1: \"I notice that the speaker starts with a positive comment about the app, saying they like it and that it looks nicer.\"\n",
      "  \n",
      "**Expert 2:**\n",
      "- Step 1: \"I agree with Expert 1, but I also think that the second part of the statement introduces a negative sentiment, as it emphasizes that looks don't matter if functionality is lacking.\"\n",
      "\n",
      "**Expert 3:**\n",
      "- Step 1: \"I see both perspectives. The initial praise suggests a positive sentiment, but the critique on functionality casts a shadow on it, leading me to think the overall sentiment might be negative.\"\n",
      "\n",
      "**Expert 1:**\n",
      "- Step 2: \"Based on the initial praise, I might lean towards a mixed sentiment, but the criticism is quite strong, which could indicate a negative overall feeling.\"\n",
      "\n",
      "**Expert 2:**\n",
      "- Step 2: \"Yes, the negative part seems to dominate toward the end of the statement. I would argue that the sentiment overall leans more towards negative due to the emphasis on functionality.\"\n",
      "\n",
      "**Expert 3:**\n",
      "- Step 2: \"I think we are aligning on the negative aspect here. While there is a positive start, the ultimate conclusion about functionality is critical.\"\n",
      "\n",
      "**Expert 1:**\n",
      "- Step 3: \"To summarize, despite some positive language, the essential message is negative because it highlights dysfunctionality.\"\n",
      "\n",
      "**Expert 2:**\n",
      "- Step 3: \"I concur that the strong critique makes the overall sentiment negative, outweighing the positive comments.\"\n",
      "\n",
      "**Expert 3:**\n",
      "- Step 3: \"Final consensus: the sentiment is negative due to the focus on lack of functionality despite the positive remark about aesthetics.\"\n",
      "\n",
      "### Result in JSON Format\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"expertDiscussion\": [\n",
      "    {\n",
      "      \"expert\": 1,\n",
      "      \"thoughts\": \"The speaker starts with a positive comment about the app, saying they like it and that it looks nicer.\"\n",
      "    },\n",
      "    {\n",
      "      \"expert\": 2,\n",
      "      \"thoughts\": \"While the beginning is positive, the latter part indicates a strong criticism about functionality which introduces a negative sentiment.\"\n",
      "    },\n",
      "    {\n",
      "      \"expert\": 3,\n",
      "      \"thoughts\": \"The initial praise is there, but the focus on the app's drawbacks leads to a negative overall sentiment.\"\n",
      "    },\n",
      "    {\n",
      "      \"expert\": 1,\n",
      "      \"thoughts\": \"The negative criticism stands out more, indicating a more negative sentiment despite the initial positivity.\"\n",
      "    },\n",
      "    {\n",
      "      \"expert\": 2,\n",
      "      \"thoughts\": \"The critique on functionality clearly dominates the sentiment, confirming it's negative overall.\"\n",
      "    },\n",
      "    {\n",
      "      \"expert\": 3,\n",
      "      \"thoughts\": \"Our conclusions align; the sentiment is indeed negative due to the greater emphasis on negative aspects.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "``` \n",
      "\n",
      " {'completion_tokens': 622, 'prompt_tokens': 120, 'total_tokens': 742, 'completion_tokens_details': CompletionTokensDetails(audio_tokens=0, reasoning_tokens=0, accepted_prediction_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0), 'total_cost': 0.00039119999999999997}\n"
     ]
    }
   ],
   "source": [
    "print(result, \"\\n\\n\", usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel GPT\n",
    "\n",
    "- https://github.com/holarissun/PanelGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, usage =call_openai.chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "3 experts are discussing the question with a panel discussion, trying to solve it step by step, and make sure the result is correct and avoid penalty.\n",
    "\n",
    "The question is...                        \n",
    "            \n",
    "```gostei do app, ficou mas bonito, mas não adiante ser bonito se não funciona para nada```\n",
    "Qual é os sentimento no texto. positivo, negativo ou neutro?\n",
    "\n",
    "return the result in json format with the sentiment and expert discussion\n",
    "\"\"\"\n",
    "\n",
    ",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"sentiment\": \"negativo\",\n",
      "  \"expert_discussion\": [\n",
      "    {\n",
      "      \"expert\": \"Linguist Expert\",\n",
      "      \"comment\": \"O texto apresenta uma mistura de sentimentos, elogia a estética do app mas em seguida critica sua funcionalidade. A crítica sobre a falta de funcionalidade é mais forte, resultando em um sentimento negativo geral.\"\n",
      "    },\n",
      "    {\n",
      "      \"expert\": \"Psychologist Expert\",\n",
      "      \"comment\": \"A ambiguidade do texto mostra uma mistura de sentimentos, com uma ideia positiva inicial seguida por uma avaliação negativa. Isso pode indicar frustração ou decepção.\"\n",
      "    },\n",
      "    {\n",
      "      \"expert\": \"Tech Expert\",\n",
      "      \"comment\": \"A crítica sobre a falta de funcionalidade do app é um ponto crucial. Mesmo com elogios à estética, a falta de utilidade é um problema grave no contexto da tecnologia, o que leva a um sentimento negativo.\"\n",
      "    }\n",
      "  ]\n",
      "} \n",
      "\n",
      " {'completion_tokens': 224, 'prompt_tokens': 102, 'total_tokens': 326, 'total_cost': 0.00038700000000000003}\n"
     ]
    }
   ],
   "source": [
    "print(result, \"\\n\\n\", usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcition Calls + ToT\n",
    "\n",
    "\n",
    "- Tree of thoughtg: \n",
    "    - https://www.promptingguide.ai/techniques/tot\n",
    "    - https://github.com/dave1010/tree-of-thought-prompting\n",
    "- Functions call: \n",
    "    - https://www.promptingguide.ai/applications/function_calling\n",
    "    - https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-function-calling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"sentiment_analyzer\",\n",
    "            \"description\": \"Extract sentiments of phrases\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"sentiment\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\":['negative', 'neutral', 'positive'],\n",
    "                        # \"description\": \"Sentiment in the phrase\",\n",
    "                        \"description\":\"\"\"Imagine three different experts are answering this question.\n",
    "All experts will write down 1 step of their thinking,\n",
    "then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realises they're wrong at any point then they leave.\"\"\"\n",
    "                    },\n",
    "                    \"argumentation\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"description\": \"argument\",\n",
    "                        },\n",
    "                },\n",
    "                \"required\": [\"sentiment\",\"argumentation\"],\n",
    "            },\n",
    "        },   \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " {'completion_tokens': 64,\n",
       "  'prompt_tokens': 149,\n",
       "  'total_tokens': 213,\n",
       "  'total_cost': 0.0001705})"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_openai.chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\" gostei do app, ficou mas bonito, mas não adiante ser bonito se não funciona para nada \"\"\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools = tools,\n",
    "    tool_choice=\"auto\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = call_openai.full_chat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [ChatCompletionMessageToolCall(id='call_x9r5GdQb5XdsDkmMApjVwAHA', function=Function(arguments='{\"sentiment\":\"negative\",\"argumentation\":\"O usuário gostou da aparência do aplicativo, mas está insatisfeito com a funcionalidade. Ele acredita que a estética não é suficiente se o aplicativo não for funcional.\"}', name='sentiment_analyzer'), type='function')]}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(rr.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"sentiment\":\"negative\",\"argumentation\":\"O usuário gostou da aparência do aplicativo, mas está insatisfeito com a funcionalidade. Ele acredita que a estética não é suficiente se o aplicativo não for funcional.\"}'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.choices[0].message.tool_calls[0].function.arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 747 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('\\n{\\n  \"sentimento\": \"negativo\",\\n  \"argumento\": \"O app não funciona\"\\n}',\n",
       " {'completion_tokens': 23,\n",
       "  'prompt_tokens': 66,\n",
       "  'total_tokens': 89,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_tokens_details': None,\n",
       "  'total_cost': 0.000145})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "call_openai.completion(model=\"gpt-3.5-turbo-instruct\", max_tokens =400, prompt=\"\"\"\n",
    "Determine o tipo de sentimento, positivo, negativo, neutro do texto a seguir.\n",
    "\n",
    "```gostei do app, ficou mas bonito, mas não adiante ser bonito se não funciona para nada```\n",
    "\n",
    "retorne o resultado num json com chaves, sentimento, argumento.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini - OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"GEMINI_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gemini-1.5-pro\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"}\n",
    "  ],\n",
    "  stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id=None, choices=[Choice(finish_reason=None, index=0, logprobs=None, message=ChatCompletionMessage(content='How can I help you today?\\n', refusal=None, role='assistant', function_call=None, tool_calls=None), finishReason='stop')], created=1735113412, model='gemini-1.5-pro', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=None, prompt_tokens=None, total_tokens=None, completion_tokens_details=None, prompt_tokens_details=None, completionTokens=8, promptTokens=3, totalTokens=11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceDelta(content='Hello', function_call=None, refusal=None, role='assistant', tool_calls=[])\n",
      "ChoiceDelta(content=' there! How can I help you today?\\n', function_call=None, refusal=None, role='assistant', tool_calls=[])\n"
     ]
    }
   ],
   "source": [
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.51.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: C:\\Users\\caanp\\OneDrive\\MBA\\Repositorio\\GenAI_MBA\\.venv\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: crewai, embedchain, instructor, langchain-openai, litellm, mem0ai, src\n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
